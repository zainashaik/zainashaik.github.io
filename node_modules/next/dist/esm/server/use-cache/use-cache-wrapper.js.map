{"version":3,"sources":["../../../src/server/use-cache/use-cache-wrapper.ts"],"sourcesContent":["import type { DeepReadonly } from '../../shared/lib/deep-readonly'\n/* eslint-disable import/no-extraneous-dependencies */\nimport {\n  renderToReadableStream,\n  decodeReply,\n  createTemporaryReferenceSet as createServerTemporaryReferenceSet,\n} from 'react-server-dom-webpack/server.edge'\n/* eslint-disable import/no-extraneous-dependencies */\nimport {\n  createFromReadableStream,\n  encodeReply,\n  createTemporaryReferenceSet as createClientTemporaryReferenceSet,\n} from 'react-server-dom-webpack/client.edge'\n\nimport type { WorkStore } from '../app-render/work-async-storage.external'\nimport { workAsyncStorage } from '../app-render/work-async-storage.external'\nimport type {\n  UseCacheStore,\n  WorkUnitStore,\n} from '../app-render/work-unit-async-storage.external'\nimport {\n  getRenderResumeDataCache,\n  getPrerenderResumeDataCache,\n  workUnitAsyncStorage,\n} from '../app-render/work-unit-async-storage.external'\nimport { runInCleanSnapshot } from '../app-render/clean-async-snapshot.external'\n\nimport { makeHangingPromise } from '../dynamic-rendering-utils'\n\nimport type { ClientReferenceManifestForRsc } from '../../build/webpack/plugins/flight-manifest-plugin'\n\nimport {\n  getClientReferenceManifestForRsc,\n  getServerModuleMap,\n} from '../app-render/encryption-utils'\nimport DefaultCacheHandler from '../lib/cache-handlers/default'\nimport type { CacheHandler, CacheEntry } from '../lib/cache-handlers/types'\nimport type { CacheSignal } from '../app-render/cache-signal'\n\nconst isEdgeRuntime = process.env.NEXT_RUNTIME === 'edge'\n\n// If the expire time is less than .\nconst DYNAMIC_EXPIRE = 300\n\nconst cacheHandlersSymbol = Symbol.for('@next/cache-handlers')\nconst _globalThis: typeof globalThis & {\n  [cacheHandlersSymbol]?: {\n    RemoteCache?: CacheHandler\n    DefaultCache?: CacheHandler\n  }\n  __nextCacheHandlers?: Record<string, CacheHandler>\n} = globalThis\n\nconst cacheHandlerMap: Map<string, CacheHandler> = new Map([\n  [\n    'default',\n    _globalThis[cacheHandlersSymbol]?.DefaultCache || DefaultCacheHandler,\n  ],\n  [\n    'remote',\n    // in dev remote maps to default handler\n    // and is meant to be overridden in prod\n    _globalThis[cacheHandlersSymbol]?.RemoteCache || DefaultCacheHandler,\n  ],\n])\n\nfunction generateCacheEntry(\n  workStore: WorkStore,\n  outerWorkUnitStore: WorkUnitStore | undefined,\n  clientReferenceManifest: DeepReadonly<ClientReferenceManifestForRsc>,\n  encodedArguments: FormData | string,\n  fn: any\n): Promise<[ReadableStream, Promise<CacheEntry>]> {\n  // We need to run this inside a clean AsyncLocalStorage snapshot so that the cache\n  // generation cannot read anything from the context we're currently executing which\n  // might include request specific things like cookies() inside a React.cache().\n  // Note: It is important that we await at least once before this because it lets us\n  // pop out of any stack specific contexts as well - aka \"Sync\" Local Storage.\n  return runInCleanSnapshot(\n    generateCacheEntryWithRestoredWorkStore,\n    workStore,\n    outerWorkUnitStore,\n    clientReferenceManifest,\n    encodedArguments,\n    fn\n  )\n}\n\nfunction generateCacheEntryWithRestoredWorkStore(\n  workStore: WorkStore,\n  outerWorkUnitStore: WorkUnitStore | undefined,\n  clientReferenceManifest: DeepReadonly<ClientReferenceManifestForRsc>,\n  encodedArguments: FormData | string,\n  fn: any\n) {\n  // Since we cleared the AsyncLocalStorage we need to restore the workStore.\n  // Note: We explicitly don't restore the RequestStore nor the PrerenderStore.\n  // We don't want any request specific information leaking an we don't want to create a\n  // bloated fake request mock for every cache call. So any feature that currently lives\n  // in RequestStore but should be available to Caches need to move to WorkStore.\n  // PrerenderStore is not needed inside the cache scope because the outer most one will\n  // be the one to report its result to the outer Prerender.\n  return workAsyncStorage.run(\n    workStore,\n    generateCacheEntryWithCacheContext,\n    workStore,\n    outerWorkUnitStore,\n    clientReferenceManifest,\n    encodedArguments,\n    fn\n  )\n}\n\nfunction generateCacheEntryWithCacheContext(\n  workStore: WorkStore,\n  outerWorkUnitStore: WorkUnitStore | undefined,\n  clientReferenceManifest: DeepReadonly<ClientReferenceManifestForRsc>,\n  encodedArguments: FormData | string,\n  fn: any\n) {\n  if (!workStore.cacheLifeProfiles) {\n    throw new Error(\n      'cacheLifeProfiles should always be provided. This is a bug in Next.js.'\n    )\n  }\n  const defaultCacheLife = workStore.cacheLifeProfiles['default']\n  if (\n    !defaultCacheLife ||\n    defaultCacheLife.revalidate == null ||\n    defaultCacheLife.expire == null ||\n    defaultCacheLife.stale == null\n  ) {\n    throw new Error(\n      'A default cacheLife profile must always be provided. This is a bug in Next.js.'\n    )\n  }\n\n  // Initialize the Store for this Cache entry.\n  const cacheStore: UseCacheStore = {\n    type: 'cache',\n    phase: 'render',\n    implicitTags:\n      outerWorkUnitStore === undefined ||\n      outerWorkUnitStore.type === 'unstable-cache'\n        ? []\n        : outerWorkUnitStore.implicitTags,\n    revalidate: defaultCacheLife.revalidate,\n    expire: defaultCacheLife.expire,\n    stale: defaultCacheLife.stale,\n    explicitRevalidate: undefined,\n    explicitExpire: undefined,\n    explicitStale: undefined,\n    tags: null,\n  }\n  return workUnitAsyncStorage.run(\n    cacheStore,\n    generateCacheEntryImpl,\n    workStore,\n    outerWorkUnitStore,\n    cacheStore,\n    clientReferenceManifest,\n    encodedArguments,\n    fn\n  )\n}\n\nfunction propagateCacheLifeAndTags(\n  workUnitStore: WorkUnitStore | undefined,\n  entry: CacheEntry\n): void {\n  if (\n    workUnitStore &&\n    (workUnitStore.type === 'cache' ||\n      workUnitStore.type === 'prerender' ||\n      workUnitStore.type === 'prerender-ppr' ||\n      workUnitStore.type === 'prerender-legacy')\n  ) {\n    // Propagate tags and revalidate upwards\n    const outerTags = workUnitStore.tags ?? (workUnitStore.tags = [])\n    const entryTags = entry.tags\n    for (let i = 0; i < entryTags.length; i++) {\n      const tag = entryTags[i]\n      if (!outerTags.includes(tag)) {\n        outerTags.push(tag)\n      }\n    }\n    if (workUnitStore.stale > entry.stale) {\n      workUnitStore.stale = entry.stale\n    }\n    if (workUnitStore.revalidate > entry.revalidate) {\n      workUnitStore.revalidate = entry.revalidate\n    }\n    if (workUnitStore.expire > entry.expire) {\n      workUnitStore.expire = entry.expire\n    }\n  }\n}\n\nasync function collectResult(\n  savedStream: ReadableStream,\n  outerWorkUnitStore: WorkUnitStore | undefined,\n  innerCacheStore: UseCacheStore,\n  startTime: number,\n  errors: Array<unknown>, // This is a live array that gets pushed into.,\n  timer: any\n): Promise<CacheEntry> {\n  // We create a buffered stream that collects all chunks until the end to\n  // ensure that RSC has finished rendering and therefore we have collected\n  // all tags. In the future the RSC API might allow for the equivalent of\n  // the allReady Promise that exists on SSR streams.\n  //\n  // If something errored or rejected anywhere in the render, we close\n  // the stream as errored. This lets a CacheHandler choose to save the\n  // partial result up until that point for future hits for a while to avoid\n  // unnecessary retries or not to retry. We use the end of the stream for\n  // this to avoid another complicated side-channel. A receiver has to consider\n  // that the stream might also error for other reasons anyway such as losing\n  // connection.\n\n  const buffer: any[] = []\n  const reader = savedStream.getReader()\n  for (let entry; !(entry = await reader.read()).done; ) {\n    buffer.push(entry.value)\n  }\n\n  let idx = 0\n  const bufferStream = new ReadableStream({\n    pull(controller) {\n      if (idx < buffer.length) {\n        controller.enqueue(buffer[idx++])\n      } else if (errors.length > 0) {\n        // TODO: Should we use AggregateError here?\n        controller.error(errors[0])\n      } else {\n        controller.close()\n      }\n    },\n  })\n\n  const collectedTags = innerCacheStore.tags\n  // If cacheLife() was used to set an explicit revalidate time we use that.\n  // Otherwise, we use the lowest of all inner fetch()/unstable_cache() or nested \"use cache\".\n  // If they're lower than our default.\n  const collectedRevalidate =\n    innerCacheStore.explicitRevalidate !== undefined\n      ? innerCacheStore.explicitRevalidate\n      : innerCacheStore.revalidate\n  const collectedExpire =\n    innerCacheStore.explicitExpire !== undefined\n      ? innerCacheStore.explicitExpire\n      : innerCacheStore.expire\n  const collectedStale =\n    innerCacheStore.explicitStale !== undefined\n      ? innerCacheStore.explicitStale\n      : innerCacheStore.stale\n\n  const entry = {\n    value: bufferStream,\n    timestamp: startTime,\n    revalidate: collectedRevalidate,\n    expire: collectedExpire,\n    stale: collectedStale,\n    tags: collectedTags === null ? [] : collectedTags,\n  }\n  // Propagate tags/revalidate to the parent context.\n  propagateCacheLifeAndTags(outerWorkUnitStore, entry)\n\n  const cacheSignal =\n    outerWorkUnitStore && outerWorkUnitStore.type === 'prerender'\n      ? outerWorkUnitStore.cacheSignal\n      : null\n  if (cacheSignal) {\n    cacheSignal.endRead()\n  }\n\n  if (timer !== undefined) {\n    clearTimeout(timer)\n  }\n\n  return entry\n}\n\nasync function generateCacheEntryImpl(\n  workStore: WorkStore,\n  outerWorkUnitStore: WorkUnitStore | undefined,\n  innerCacheStore: UseCacheStore,\n  clientReferenceManifest: DeepReadonly<ClientReferenceManifestForRsc>,\n  encodedArguments: FormData | string,\n  fn: any\n): Promise<[ReadableStream, Promise<CacheEntry>]> {\n  const temporaryReferences = createServerTemporaryReferenceSet()\n\n  const [, , args] = await decodeReply<any[]>(\n    encodedArguments,\n    getServerModuleMap(),\n    {\n      temporaryReferences,\n    }\n  )\n\n  // Track the timestamp when we started copmuting the result.\n  const startTime = performance.timeOrigin + performance.now()\n  // Invoke the inner function to load a new result.\n  const result = fn.apply(null, args)\n\n  let errors: Array<unknown> = []\n\n  let timer = undefined\n  const controller = new AbortController()\n  if (workStore.isStaticGeneration) {\n    // If we're prerendering, we give you 50 seconds to fill a cache entry. Otherwise\n    // we assume you stalled on hanging input and deopt. This needs to be lower than\n    // just the general timeout of 60 seconds.\n    timer = setTimeout(() => {\n      controller.abort(\n        new Error(\n          'Filling a cache during prerender timed out, likely because request-specific arguments such as ' +\n            'params, searchParams, cookies() or dynamic data were used inside \"use cache\".'\n        )\n      )\n    }, 50000)\n  }\n\n  const stream = renderToReadableStream(\n    result,\n    clientReferenceManifest.clientModules,\n    {\n      environmentName: 'Cache',\n      signal: controller.signal,\n      temporaryReferences,\n      onError(error: unknown) {\n        // Report the error.\n        console.error(error)\n        errors.push(error)\n      },\n    }\n  )\n\n  const [returnStream, savedStream] = stream.tee()\n\n  const promiseOfCacheEntry = collectResult(\n    savedStream,\n    outerWorkUnitStore,\n    innerCacheStore,\n    startTime,\n    errors,\n    timer\n  )\n\n  // Return the stream as we're creating it. This means that if it ends up\n  // erroring we cannot return a stale-while-error version but it allows\n  // streaming back the result earlier.\n  return [returnStream, promiseOfCacheEntry]\n}\n\nfunction cloneCacheEntry(entry: CacheEntry): [CacheEntry, CacheEntry] {\n  const [streamA, streamB] = entry.value.tee()\n  entry.value = streamA\n  const clonedEntry: CacheEntry = {\n    value: streamB,\n    timestamp: entry.timestamp,\n    revalidate: entry.revalidate,\n    expire: entry.expire,\n    stale: entry.stale,\n    tags: entry.tags,\n  }\n  return [entry, clonedEntry]\n}\n\nasync function clonePendingCacheEntry(\n  pendingCacheEntry: Promise<CacheEntry>\n): Promise<[CacheEntry, CacheEntry]> {\n  const entry = await pendingCacheEntry\n  return cloneCacheEntry(entry)\n}\n\nasync function getNthCacheEntry(\n  split: Promise<[CacheEntry, CacheEntry]>,\n  i: number\n): Promise<CacheEntry> {\n  return (await split)[i]\n}\n\nasync function encodeFormData(formData: FormData): Promise<string> {\n  let result = ''\n  for (let [key, value] of formData) {\n    // We don't need this key to be serializable but from a security perspective it should not be\n    // possible to generate a string that looks the same from a different structure. To ensure this\n    // we need a delimeter between fields but just using a delimeter is not enough since a string\n    // might contain that delimeter. We use the length of each field as the delimeter to avoid\n    // escaping the values.\n    result += key.length.toString(16) + ':' + key\n    let stringValue\n    if (typeof value === 'string') {\n      stringValue = value\n    } else {\n      // The FormData might contain binary data that is not valid UTF-8 so this cache\n      // key may generate a UCS-2 string. Passing this to another service needs to be\n      // aware that the key might not be compatible.\n      const arrayBuffer = await value.arrayBuffer()\n      if (arrayBuffer.byteLength % 2 === 0) {\n        stringValue = String.fromCodePoint(...new Uint16Array(arrayBuffer))\n      } else {\n        stringValue =\n          String.fromCodePoint(\n            ...new Uint16Array(arrayBuffer, 0, (arrayBuffer.byteLength - 1) / 2)\n          ) +\n          String.fromCodePoint(\n            new Uint8Array(arrayBuffer, arrayBuffer.byteLength - 1, 1)[0]\n          )\n      }\n    }\n    result += stringValue.length.toString(16) + ':' + stringValue\n  }\n  return result\n}\n\nfunction createTrackedReadableStream(\n  stream: ReadableStream,\n  cacheSignal: CacheSignal\n) {\n  const reader = stream.getReader()\n  return new ReadableStream({\n    async pull(controller) {\n      const { done, value } = await reader.read()\n      if (done) {\n        controller.close()\n        cacheSignal.endRead()\n      } else {\n        controller.enqueue(value)\n      }\n    },\n  })\n}\n\nexport function cache(kind: string, id: string, fn: any) {\n  if (!process.env.__NEXT_DYNAMIC_IO) {\n    throw new Error(\n      '\"use cache\" is only available with the experimental.dynamicIO config.'\n    )\n  }\n  for (const [key, value] of Object.entries(\n    _globalThis.__nextCacheHandlers || {}\n  )) {\n    cacheHandlerMap.set(key, value as CacheHandler)\n  }\n  const cacheHandler = cacheHandlerMap.get(kind)\n\n  if (cacheHandler === undefined) {\n    throw new Error('Unknown cache handler: ' + kind)\n  }\n  const name = fn.name\n  const cachedFn = {\n    [name]: async function (...args: any[]) {\n      const workStore = workAsyncStorage.getStore()\n      if (workStore === undefined) {\n        throw new Error(\n          '\"use cache\" cannot be used outside of App Router. Expected a WorkStore.'\n        )\n      }\n\n      const workUnitStore = workUnitAsyncStorage.getStore()\n\n      // Get the clientReferenceManifest while we're still in the outer Context.\n      // In case getClientReferenceManifestSingleton is implemented using AsyncLocalStorage.\n      const clientReferenceManifest = getClientReferenceManifestForRsc()\n\n      // Because the Action ID is not yet unique per implementation of that Action we can't\n      // safely reuse the results across builds yet. In the meantime we add the buildId to the\n      // arguments as a seed to ensure they're not reused. Remove this once Action IDs hash\n      // the implementation.\n      const buildId = workStore.buildId\n\n      let abortHangingInputSignal: null | AbortSignal = null\n      if (workUnitStore && workUnitStore.type === 'prerender') {\n        // In a prerender, we may end up with hanging Promises as inputs due them stalling\n        // on connection() or because they're loading dynamic data. In that case we need to\n        // abort the encoding of the arguments since they'll never complete.\n        const controller = new AbortController()\n        abortHangingInputSignal = controller.signal\n        if (workUnitStore.cacheSignal) {\n          // If we have a cacheSignal it means we're in a prospective render. If the input\n          // we're waiting on is coming from another cache, we do want to wait for it so that\n          // we can resolve this cache entry too.\n          workUnitStore.cacheSignal.inputReady().then(() => {\n            controller.abort()\n          })\n        } else {\n          // Otherwise we're in the final render and we should already have all our caches\n          // filled. We might still be waiting on some microtasks so we wait one tick before\n          // giving up. When we give up, we still want to render the content of this cache\n          // as deeply as we can so that we can suspend as deeply as possible in the tree\n          // or not at all if we don't end up waiting for the input.\n          process.nextTick(() => controller.abort())\n        }\n      }\n\n      const temporaryReferences = createClientTemporaryReferenceSet()\n      const encodedArguments: FormData | string = await encodeReply(\n        [buildId, id, args],\n        // Right now this is enough to cause the input to generate hanging Promises\n        // but that's really due to what is probably a React bug in decodeReply.\n        // If that's fixed we may need a different strategy. We can also just skip\n        // the serialization/cache in this scenario and pass-through raw objects.\n        abortHangingInputSignal\n          ? {\n              temporaryReferences,\n              signal: abortHangingInputSignal,\n            }\n          : {\n              temporaryReferences,\n            }\n      )\n\n      const serializedCacheKey =\n        typeof encodedArguments === 'string'\n          ? // Fast path for the simple case for simple inputs. We let the CacheHandler\n            // Convert it to an ArrayBuffer if it wants to.\n            encodedArguments\n          : await encodeFormData(encodedArguments)\n\n      let stream: undefined | ReadableStream = undefined\n\n      // Get an immutable and mutable versions of the resume data cache.\n      const prerenderResumeDataCache = workUnitStore\n        ? getPrerenderResumeDataCache(workUnitStore)\n        : null\n      const renderResumeDataCache = workUnitStore\n        ? getRenderResumeDataCache(workUnitStore)\n        : null\n\n      if (renderResumeDataCache) {\n        const cacheSignal =\n          workUnitStore && workUnitStore.type === 'prerender'\n            ? workUnitStore.cacheSignal\n            : null\n\n        if (cacheSignal) {\n          cacheSignal.beginRead()\n        }\n        const cachedEntry = renderResumeDataCache.cache.get(serializedCacheKey)\n        if (cachedEntry !== undefined) {\n          const existingEntry = await cachedEntry\n          propagateCacheLifeAndTags(workUnitStore, existingEntry)\n          if (\n            workUnitStore !== undefined &&\n            workUnitStore.type === 'prerender' &&\n            existingEntry !== undefined &&\n            (existingEntry.revalidate === 0 ||\n              existingEntry.expire < DYNAMIC_EXPIRE)\n          ) {\n            // In a Dynamic I/O prerender, if the cache entry has revalidate: 0 or if the\n            // expire time is under 5 minutes, then we consider this cache entry dynamic\n            // as it's not worth generating static pages for such data. It's better to leave\n            // a PPR hole that can be filled in dynamically with a potentially cached entry.\n            if (cacheSignal) {\n              cacheSignal.endRead()\n            }\n            return makeHangingPromise(\n              workUnitStore.renderSignal,\n              'dynamic \"use cache\"'\n            )\n          }\n          const [streamA, streamB] = existingEntry.value.tee()\n          existingEntry.value = streamB\n\n          if (cacheSignal) {\n            // When we have a cacheSignal we need to block on reading the cache\n            // entry before ending the read.\n            stream = createTrackedReadableStream(streamA, cacheSignal)\n          } else {\n            stream = streamA\n          }\n        } else {\n          if (cacheSignal) {\n            cacheSignal.endRead()\n          }\n        }\n      }\n\n      if (stream === undefined) {\n        const cacheSignal =\n          workUnitStore && workUnitStore.type === 'prerender'\n            ? workUnitStore.cacheSignal\n            : null\n        if (cacheSignal) {\n          // Either the cache handler or the generation can be using I/O at this point.\n          // We need to track when they start and when they complete.\n          cacheSignal.beginRead()\n        }\n\n        const implicitTags =\n          workUnitStore === undefined || workUnitStore.type === 'unstable-cache'\n            ? []\n            : workUnitStore.implicitTags\n        const entry: undefined | CacheEntry = await cacheHandler.get(\n          serializedCacheKey,\n          implicitTags\n        )\n        const currentTime = performance.timeOrigin + performance.now()\n        if (\n          workUnitStore !== undefined &&\n          workUnitStore.type === 'prerender' &&\n          entry !== undefined &&\n          (entry.revalidate === 0 || entry.expire < DYNAMIC_EXPIRE)\n        ) {\n          // In a Dynamic I/O prerender, if the cache entry has revalidate: 0 or if the\n          // expire time is under 5 minutes, then we consider this cache entry dynamic\n          // as it's not worth generating static pages for such data. It's better to leave\n          // a PPR hole that can be filled in dynamically with a potentially cached entry.\n          if (cacheSignal) {\n            cacheSignal.endRead()\n          }\n\n          return makeHangingPromise(\n            workUnitStore.renderSignal,\n            'dynamic \"use cache\"'\n          )\n        } else if (\n          entry === undefined ||\n          currentTime > entry.timestamp + entry.expire * 1000 ||\n          (workStore.isStaticGeneration &&\n            currentTime > entry.timestamp + entry.revalidate * 1000)\n        ) {\n          // Miss. Generate a new result.\n\n          // If the cache entry is stale and we're prerendering, we don't want to use the\n          // stale entry since it would unnecessarily need to shorten the lifetime of the\n          // prerender. We're not time constrained here so we can re-generated it now.\n\n          // We need to run this inside a clean AsyncLocalStorage snapshot so that the cache\n          // generation cannot read anything from the context we're currently executing which\n          // might include request specific things like cookies() inside a React.cache().\n          // Note: It is important that we await at least once before this because it lets us\n          // pop out of any stack specific contexts as well - aka \"Sync\" Local Storage.\n\n          const [newStream, pendingCacheEntry] = await generateCacheEntry(\n            workStore,\n            workUnitStore,\n            clientReferenceManifest,\n            encodedArguments,\n            fn\n          )\n\n          let savedCacheEntry\n          if (prerenderResumeDataCache) {\n            // Create a clone that goes into the cache scope memory cache.\n            const split = clonePendingCacheEntry(pendingCacheEntry)\n            savedCacheEntry = getNthCacheEntry(split, 0)\n            prerenderResumeDataCache.cache.set(\n              serializedCacheKey,\n              getNthCacheEntry(split, 1)\n            )\n          } else {\n            savedCacheEntry = pendingCacheEntry\n          }\n\n          const promise = cacheHandler.set(serializedCacheKey, savedCacheEntry)\n\n          if (!workStore.pendingRevalidateWrites) {\n            workStore.pendingRevalidateWrites = []\n          }\n          workStore.pendingRevalidateWrites.push(promise)\n\n          stream = newStream\n        } else {\n          propagateCacheLifeAndTags(workUnitStore, entry)\n\n          // We want to return this stream, even if it's stale.\n          stream = entry.value\n\n          // If we have a cache scope, we need to clone the entry and set it on\n          // the inner cache scope.\n          if (prerenderResumeDataCache) {\n            const [entryLeft, entryRight] = cloneCacheEntry(entry)\n            if (cacheSignal) {\n              stream = createTrackedReadableStream(entryLeft.value, cacheSignal)\n            } else {\n              stream = entryLeft.value\n            }\n\n            prerenderResumeDataCache.cache.set(\n              serializedCacheKey,\n              Promise.resolve(entryRight)\n            )\n          } else {\n            // If we're not regenerating we need to signal that we've finished\n            // putting the entry into the cache scope at this point. Otherwise we do\n            // that inside generateCacheEntry.\n            cacheSignal?.endRead()\n          }\n\n          if (currentTime > entry.timestamp + entry.revalidate * 1000) {\n            // If this is stale, and we're not in a prerender (i.e. this is dynamic render),\n            // then we should warm up the cache with a fresh revalidated entry.\n            const [ignoredStream, pendingCacheEntry] = await generateCacheEntry(\n              workStore,\n              undefined, // This is not running within the context of this unit.\n              clientReferenceManifest,\n              encodedArguments,\n              fn\n            )\n\n            let savedCacheEntry: Promise<CacheEntry>\n            if (prerenderResumeDataCache) {\n              const split = clonePendingCacheEntry(pendingCacheEntry)\n              savedCacheEntry = getNthCacheEntry(split, 0)\n              prerenderResumeDataCache.cache.set(\n                serializedCacheKey,\n                getNthCacheEntry(split, 1)\n              )\n            } else {\n              savedCacheEntry = pendingCacheEntry\n            }\n\n            const promise = cacheHandler.set(\n              serializedCacheKey,\n              savedCacheEntry\n            )\n\n            if (!workStore.pendingRevalidateWrites) {\n              workStore.pendingRevalidateWrites = []\n            }\n            workStore.pendingRevalidateWrites.push(promise)\n\n            await ignoredStream.cancel()\n          }\n        }\n      }\n\n      // Logs are replayed even if it's a hit - to ensure we see them on the client eventually.\n      // If we didn't then the client wouldn't see the logs if it was seeded from a prewarm that\n      // never made it to the client. However, this also means that you see logs even when the\n      // cached function isn't actually re-executed. We should instead ensure prewarms always\n      // make it to the client. Another issue is that this will cause double logging in the\n      // server terminal. Once while generating the cache entry and once when replaying it on\n      // the server, which is required to pick it up for replaying again on the client.\n      const replayConsoleLogs = true\n\n      const serverConsumerManifest = {\n        // moduleLoading must be null because we don't want to trigger preloads of ClientReferences\n        // to be added to the consumer. Instead, we'll wait for any ClientReference to be emitted\n        // which themselves will handle the preloading.\n        moduleLoading: null,\n        moduleMap: isEdgeRuntime\n          ? clientReferenceManifest.edgeRscModuleMapping\n          : clientReferenceManifest.rscModuleMapping,\n        serverModuleMap: getServerModuleMap(),\n      }\n\n      return createFromReadableStream(stream, {\n        serverConsumerManifest,\n        temporaryReferences,\n        replayConsoleLogs,\n        environmentName: 'Cache',\n      })\n    },\n  }[name]\n  return cachedFn\n}\n"],"names":["_globalThis","renderToReadableStream","decodeReply","createTemporaryReferenceSet","createServerTemporaryReferenceSet","createFromReadableStream","encodeReply","createClientTemporaryReferenceSet","workAsyncStorage","getRenderResumeDataCache","getPrerenderResumeDataCache","workUnitAsyncStorage","runInCleanSnapshot","makeHangingPromise","getClientReferenceManifestForRsc","getServerModuleMap","DefaultCacheHandler","isEdgeRuntime","process","env","NEXT_RUNTIME","DYNAMIC_EXPIRE","cacheHandlersSymbol","Symbol","for","globalThis","cacheHandlerMap","Map","DefaultCache","RemoteCache","generateCacheEntry","workStore","outerWorkUnitStore","clientReferenceManifest","encodedArguments","fn","generateCacheEntryWithRestoredWorkStore","run","generateCacheEntryWithCacheContext","cacheLifeProfiles","Error","defaultCacheLife","revalidate","expire","stale","cacheStore","type","phase","implicitTags","undefined","explicitRevalidate","explicitExpire","explicitStale","tags","generateCacheEntryImpl","propagateCacheLifeAndTags","workUnitStore","entry","outerTags","entryTags","i","length","tag","includes","push","collectResult","savedStream","innerCacheStore","startTime","errors","timer","buffer","reader","getReader","read","done","value","idx","bufferStream","ReadableStream","pull","controller","enqueue","error","close","collectedTags","collectedRevalidate","collectedExpire","collectedStale","timestamp","cacheSignal","endRead","clearTimeout","temporaryReferences","args","performance","timeOrigin","now","result","apply","AbortController","isStaticGeneration","setTimeout","abort","stream","clientModules","environmentName","signal","onError","console","returnStream","tee","promiseOfCacheEntry","cloneCacheEntry","streamA","streamB","clonedEntry","clonePendingCacheEntry","pendingCacheEntry","getNthCacheEntry","split","encodeFormData","formData","key","toString","stringValue","arrayBuffer","byteLength","String","fromCodePoint","Uint16Array","Uint8Array","createTrackedReadableStream","cache","kind","id","__NEXT_DYNAMIC_IO","Object","entries","__nextCacheHandlers","set","cacheHandler","get","name","cachedFn","getStore","buildId","abortHangingInputSignal","inputReady","then","nextTick","serializedCacheKey","prerenderResumeDataCache","renderResumeDataCache","beginRead","cachedEntry","existingEntry","renderSignal","currentTime","newStream","savedCacheEntry","promise","pendingRevalidateWrites","entryLeft","entryRight","Promise","resolve","ignoredStream","cancel","replayConsoleLogs","serverConsumerManifest","moduleLoading","moduleMap","edgeRscModuleMapping","rscModuleMapping","serverModuleMap"],"mappings":"IAwDIA,iCAIA,wCAAwC;AACxC,wCAAwC;AACxCA;AA7DJ,oDAAoD,GACpD,SACEC,sBAAsB,EACtBC,WAAW,EACXC,+BAA+BC,iCAAiC,QAC3D,uCAAsC;AAC7C,oDAAoD,GACpD,SACEC,wBAAwB,EACxBC,WAAW,EACXH,+BAA+BI,iCAAiC,QAC3D,uCAAsC;AAG7C,SAASC,gBAAgB,QAAQ,4CAA2C;AAK5E,SACEC,wBAAwB,EACxBC,2BAA2B,EAC3BC,oBAAoB,QACf,iDAAgD;AACvD,SAASC,kBAAkB,QAAQ,8CAA6C;AAEhF,SAASC,kBAAkB,QAAQ,6BAA4B;AAI/D,SACEC,gCAAgC,EAChCC,kBAAkB,QACb,iCAAgC;AACvC,OAAOC,yBAAyB,gCAA+B;AAI/D,MAAMC,gBAAgBC,QAAQC,GAAG,CAACC,YAAY,KAAK;AAEnD,oCAAoC;AACpC,MAAMC,iBAAiB;AAEvB,MAAMC,sBAAsBC,OAAOC,GAAG,CAAC;AACvC,MAAMxB,cAMFyB;AAEJ,MAAMC,kBAA6C,IAAIC,IAAI;IACzD;QACE;QACA3B,EAAAA,kCAAAA,WAAW,CAACsB,oBAAoB,qBAAhCtB,gCAAkC4B,YAAY,KAAIZ;KACnD;IACD;QACE;QAGAhB,EAAAA,mCAAAA,WAAW,CAACsB,oBAAoB,qBAAhCtB,iCAAkC6B,WAAW,KAAIb;KAClD;CACF;AAED,SAASc,mBACPC,SAAoB,EACpBC,kBAA6C,EAC7CC,uBAAoE,EACpEC,gBAAmC,EACnCC,EAAO;IAEP,kFAAkF;IAClF,mFAAmF;IACnF,+EAA+E;IAC/E,mFAAmF;IACnF,6EAA6E;IAC7E,OAAOvB,mBACLwB,yCACAL,WACAC,oBACAC,yBACAC,kBACAC;AAEJ;AAEA,SAASC,wCACPL,SAAoB,EACpBC,kBAA6C,EAC7CC,uBAAoE,EACpEC,gBAAmC,EACnCC,EAAO;IAEP,2EAA2E;IAC3E,6EAA6E;IAC7E,sFAAsF;IACtF,sFAAsF;IACtF,+EAA+E;IAC/E,sFAAsF;IACtF,0DAA0D;IAC1D,OAAO3B,iBAAiB6B,GAAG,CACzBN,WACAO,oCACAP,WACAC,oBACAC,yBACAC,kBACAC;AAEJ;AAEA,SAASG,mCACPP,SAAoB,EACpBC,kBAA6C,EAC7CC,uBAAoE,EACpEC,gBAAmC,EACnCC,EAAO;IAEP,IAAI,CAACJ,UAAUQ,iBAAiB,EAAE;QAChC,MAAM,IAAIC,MACR;IAEJ;IACA,MAAMC,mBAAmBV,UAAUQ,iBAAiB,CAAC,UAAU;IAC/D,IACE,CAACE,oBACDA,iBAAiBC,UAAU,IAAI,QAC/BD,iBAAiBE,MAAM,IAAI,QAC3BF,iBAAiBG,KAAK,IAAI,MAC1B;QACA,MAAM,IAAIJ,MACR;IAEJ;IAEA,6CAA6C;IAC7C,MAAMK,aAA4B;QAChCC,MAAM;QACNC,OAAO;QACPC,cACEhB,uBAAuBiB,aACvBjB,mBAAmBc,IAAI,KAAK,mBACxB,EAAE,GACFd,mBAAmBgB,YAAY;QACrCN,YAAYD,iBAAiBC,UAAU;QACvCC,QAAQF,iBAAiBE,MAAM;QAC/BC,OAAOH,iBAAiBG,KAAK;QAC7BM,oBAAoBD;QACpBE,gBAAgBF;QAChBG,eAAeH;QACfI,MAAM;IACR;IACA,OAAO1C,qBAAqB0B,GAAG,CAC7BQ,YACAS,wBACAvB,WACAC,oBACAa,YACAZ,yBACAC,kBACAC;AAEJ;AAEA,SAASoB,0BACPC,aAAwC,EACxCC,KAAiB;IAEjB,IACED,iBACCA,CAAAA,cAAcV,IAAI,KAAK,WACtBU,cAAcV,IAAI,KAAK,eACvBU,cAAcV,IAAI,KAAK,mBACvBU,cAAcV,IAAI,KAAK,kBAAiB,GAC1C;QACA,wCAAwC;QACxC,MAAMY,YAAYF,cAAcH,IAAI,IAAKG,CAAAA,cAAcH,IAAI,GAAG,EAAE,AAAD;QAC/D,MAAMM,YAAYF,MAAMJ,IAAI;QAC5B,IAAK,IAAIO,IAAI,GAAGA,IAAID,UAAUE,MAAM,EAAED,IAAK;YACzC,MAAME,MAAMH,SAAS,CAACC,EAAE;YACxB,IAAI,CAACF,UAAUK,QAAQ,CAACD,MAAM;gBAC5BJ,UAAUM,IAAI,CAACF;YACjB;QACF;QACA,IAAIN,cAAcZ,KAAK,GAAGa,MAAMb,KAAK,EAAE;YACrCY,cAAcZ,KAAK,GAAGa,MAAMb,KAAK;QACnC;QACA,IAAIY,cAAcd,UAAU,GAAGe,MAAMf,UAAU,EAAE;YAC/Cc,cAAcd,UAAU,GAAGe,MAAMf,UAAU;QAC7C;QACA,IAAIc,cAAcb,MAAM,GAAGc,MAAMd,MAAM,EAAE;YACvCa,cAAcb,MAAM,GAAGc,MAAMd,MAAM;QACrC;IACF;AACF;AAEA,eAAesB,cACbC,WAA2B,EAC3BlC,kBAA6C,EAC7CmC,eAA8B,EAC9BC,SAAiB,EACjBC,MAAsB,EACtBC,KAAU;IAEV,wEAAwE;IACxE,yEAAyE;IACzE,wEAAwE;IACxE,mDAAmD;IACnD,EAAE;IACF,oEAAoE;IACpE,qEAAqE;IACrE,0EAA0E;IAC1E,wEAAwE;IACxE,6EAA6E;IAC7E,2EAA2E;IAC3E,cAAc;IAEd,MAAMC,SAAgB,EAAE;IACxB,MAAMC,SAASN,YAAYO,SAAS;IACpC,IAAK,IAAIhB,OAAO,CAAC,AAACA,CAAAA,QAAQ,MAAMe,OAAOE,IAAI,EAAC,EAAGC,IAAI,EAAI;QACrDJ,OAAOP,IAAI,CAACP,MAAMmB,KAAK;IACzB;IAEA,IAAIC,MAAM;IACV,MAAMC,eAAe,IAAIC,eAAe;QACtCC,MAAKC,UAAU;YACb,IAAIJ,MAAMN,OAAOV,MAAM,EAAE;gBACvBoB,WAAWC,OAAO,CAACX,MAAM,CAACM,MAAM;YAClC,OAAO,IAAIR,OAAOR,MAAM,GAAG,GAAG;gBAC5B,2CAA2C;gBAC3CoB,WAAWE,KAAK,CAACd,MAAM,CAAC,EAAE;YAC5B,OAAO;gBACLY,WAAWG,KAAK;YAClB;QACF;IACF;IAEA,MAAMC,gBAAgBlB,gBAAgBd,IAAI;IAC1C,0EAA0E;IAC1E,4FAA4F;IAC5F,qCAAqC;IACrC,MAAMiC,sBACJnB,gBAAgBjB,kBAAkB,KAAKD,YACnCkB,gBAAgBjB,kBAAkB,GAClCiB,gBAAgBzB,UAAU;IAChC,MAAM6C,kBACJpB,gBAAgBhB,cAAc,KAAKF,YAC/BkB,gBAAgBhB,cAAc,GAC9BgB,gBAAgBxB,MAAM;IAC5B,MAAM6C,iBACJrB,gBAAgBf,aAAa,KAAKH,YAC9BkB,gBAAgBf,aAAa,GAC7Be,gBAAgBvB,KAAK;IAE3B,MAAMa,QAAQ;QACZmB,OAAOE;QACPW,WAAWrB;QACX1B,YAAY4C;QACZ3C,QAAQ4C;QACR3C,OAAO4C;QACPnC,MAAMgC,kBAAkB,OAAO,EAAE,GAAGA;IACtC;IACA,mDAAmD;IACnD9B,0BAA0BvB,oBAAoByB;IAE9C,MAAMiC,cACJ1D,sBAAsBA,mBAAmBc,IAAI,KAAK,cAC9Cd,mBAAmB0D,WAAW,GAC9B;IACN,IAAIA,aAAa;QACfA,YAAYC,OAAO;IACrB;IAEA,IAAIrB,UAAUrB,WAAW;QACvB2C,aAAatB;IACf;IAEA,OAAOb;AACT;AAEA,eAAeH,uBACbvB,SAAoB,EACpBC,kBAA6C,EAC7CmC,eAA8B,EAC9BlC,uBAAoE,EACpEC,gBAAmC,EACnCC,EAAO;IAEP,MAAM0D,sBAAsBzF;IAE5B,MAAM,KAAK0F,KAAK,GAAG,MAAM5F,YACvBgC,kBACAnB,sBACA;QACE8E;IACF;IAGF,4DAA4D;IAC5D,MAAMzB,YAAY2B,YAAYC,UAAU,GAAGD,YAAYE,GAAG;IAC1D,kDAAkD;IAClD,MAAMC,SAAS/D,GAAGgE,KAAK,CAAC,MAAML;IAE9B,IAAIzB,SAAyB,EAAE;IAE/B,IAAIC,QAAQrB;IACZ,MAAMgC,aAAa,IAAImB;IACvB,IAAIrE,UAAUsE,kBAAkB,EAAE;QAChC,iFAAiF;QACjF,gFAAgF;QAChF,0CAA0C;QAC1C/B,QAAQgC,WAAW;YACjBrB,WAAWsB,KAAK,CACd,IAAI/D,MACF,mGACE;QAGR,GAAG;IACL;IAEA,MAAMgE,SAASvG,uBACbiG,QACAjE,wBAAwBwE,aAAa,EACrC;QACEC,iBAAiB;QACjBC,QAAQ1B,WAAW0B,MAAM;QACzBd;QACAe,SAAQzB,KAAc;YACpB,oBAAoB;YACpB0B,QAAQ1B,KAAK,CAACA;YACdd,OAAOL,IAAI,CAACmB;QACd;IACF;IAGF,MAAM,CAAC2B,cAAc5C,YAAY,GAAGsC,OAAOO,GAAG;IAE9C,MAAMC,sBAAsB/C,cAC1BC,aACAlC,oBACAmC,iBACAC,WACAC,QACAC;IAGF,wEAAwE;IACxE,sEAAsE;IACtE,qCAAqC;IACrC,OAAO;QAACwC;QAAcE;KAAoB;AAC5C;AAEA,SAASC,gBAAgBxD,KAAiB;IACxC,MAAM,CAACyD,SAASC,QAAQ,GAAG1D,MAAMmB,KAAK,CAACmC,GAAG;IAC1CtD,MAAMmB,KAAK,GAAGsC;IACd,MAAME,cAA0B;QAC9BxC,OAAOuC;QACP1B,WAAWhC,MAAMgC,SAAS;QAC1B/C,YAAYe,MAAMf,UAAU;QAC5BC,QAAQc,MAAMd,MAAM;QACpBC,OAAOa,MAAMb,KAAK;QAClBS,MAAMI,MAAMJ,IAAI;IAClB;IACA,OAAO;QAACI;QAAO2D;KAAY;AAC7B;AAEA,eAAeC,uBACbC,iBAAsC;IAEtC,MAAM7D,QAAQ,MAAM6D;IACpB,OAAOL,gBAAgBxD;AACzB;AAEA,eAAe8D,iBACbC,KAAwC,EACxC5D,CAAS;IAET,OAAO,AAAC,CAAA,MAAM4D,KAAI,CAAE,CAAC5D,EAAE;AACzB;AAEA,eAAe6D,eAAeC,QAAkB;IAC9C,IAAIxB,SAAS;IACb,KAAK,IAAI,CAACyB,KAAK/C,MAAM,IAAI8C,SAAU;QACjC,6FAA6F;QAC7F,+FAA+F;QAC/F,6FAA6F;QAC7F,0FAA0F;QAC1F,uBAAuB;QACvBxB,UAAUyB,IAAI9D,MAAM,CAAC+D,QAAQ,CAAC,MAAM,MAAMD;QAC1C,IAAIE;QACJ,IAAI,OAAOjD,UAAU,UAAU;YAC7BiD,cAAcjD;QAChB,OAAO;YACL,+EAA+E;YAC/E,+EAA+E;YAC/E,8CAA8C;YAC9C,MAAMkD,cAAc,MAAMlD,MAAMkD,WAAW;YAC3C,IAAIA,YAAYC,UAAU,GAAG,MAAM,GAAG;gBACpCF,cAAcG,OAAOC,aAAa,IAAI,IAAIC,YAAYJ;YACxD,OAAO;gBACLD,cACEG,OAAOC,aAAa,IACf,IAAIC,YAAYJ,aAAa,GAAG,AAACA,CAAAA,YAAYC,UAAU,GAAG,CAAA,IAAK,MAEpEC,OAAOC,aAAa,CAClB,IAAIE,WAAWL,aAAaA,YAAYC,UAAU,GAAG,GAAG,EAAE,CAAC,EAAE;YAEnE;QACF;QACA7B,UAAU2B,YAAYhE,MAAM,CAAC+D,QAAQ,CAAC,MAAM,MAAMC;IACpD;IACA,OAAO3B;AACT;AAEA,SAASkC,4BACP5B,MAAsB,EACtBd,WAAwB;IAExB,MAAMlB,SAASgC,OAAO/B,SAAS;IAC/B,OAAO,IAAIM,eAAe;QACxB,MAAMC,MAAKC,UAAU;YACnB,MAAM,EAAEN,IAAI,EAAEC,KAAK,EAAE,GAAG,MAAMJ,OAAOE,IAAI;YACzC,IAAIC,MAAM;gBACRM,WAAWG,KAAK;gBAChBM,YAAYC,OAAO;YACrB,OAAO;gBACLV,WAAWC,OAAO,CAACN;YACrB;QACF;IACF;AACF;AAEA,OAAO,SAASyD,MAAMC,IAAY,EAAEC,EAAU,EAAEpG,EAAO;IACrD,IAAI,CAACjB,QAAQC,GAAG,CAACqH,iBAAiB,EAAE;QAClC,MAAM,IAAIhG,MACR;IAEJ;IACA,KAAK,MAAM,CAACmF,KAAK/C,MAAM,IAAI6D,OAAOC,OAAO,CACvC1I,YAAY2I,mBAAmB,IAAI,CAAC,GACnC;QACDjH,gBAAgBkH,GAAG,CAACjB,KAAK/C;IAC3B;IACA,MAAMiE,eAAenH,gBAAgBoH,GAAG,CAACR;IAEzC,IAAIO,iBAAiB5F,WAAW;QAC9B,MAAM,IAAIT,MAAM,4BAA4B8F;IAC9C;IACA,MAAMS,OAAO5G,GAAG4G,IAAI;IACpB,MAAMC,WAAW;QACf,CAACD,KAAK,EAAE,eAAgB,GAAGjD,IAAW;YACpC,MAAM/D,YAAYvB,iBAAiByI,QAAQ;YAC3C,IAAIlH,cAAckB,WAAW;gBAC3B,MAAM,IAAIT,MACR;YAEJ;YAEA,MAAMgB,gBAAgB7C,qBAAqBsI,QAAQ;YAEnD,0EAA0E;YAC1E,sFAAsF;YACtF,MAAMhH,0BAA0BnB;YAEhC,qFAAqF;YACrF,wFAAwF;YACxF,qFAAqF;YACrF,sBAAsB;YACtB,MAAMoI,UAAUnH,UAAUmH,OAAO;YAEjC,IAAIC,0BAA8C;YAClD,IAAI3F,iBAAiBA,cAAcV,IAAI,KAAK,aAAa;gBACvD,kFAAkF;gBAClF,mFAAmF;gBACnF,oEAAoE;gBACpE,MAAMmC,aAAa,IAAImB;gBACvB+C,0BAA0BlE,WAAW0B,MAAM;gBAC3C,IAAInD,cAAckC,WAAW,EAAE;oBAC7B,gFAAgF;oBAChF,mFAAmF;oBACnF,uCAAuC;oBACvClC,cAAckC,WAAW,CAAC0D,UAAU,GAAGC,IAAI,CAAC;wBAC1CpE,WAAWsB,KAAK;oBAClB;gBACF,OAAO;oBACL,gFAAgF;oBAChF,kFAAkF;oBAClF,gFAAgF;oBAChF,+EAA+E;oBAC/E,0DAA0D;oBAC1DrF,QAAQoI,QAAQ,CAAC,IAAMrE,WAAWsB,KAAK;gBACzC;YACF;YAEA,MAAMV,sBAAsBtF;YAC5B,MAAM2B,mBAAsC,MAAM5B,YAChD;gBAAC4I;gBAASX;gBAAIzC;aAAK,EACnB,2EAA2E;YAC3E,wEAAwE;YACxE,0EAA0E;YAC1E,yEAAyE;YACzEqD,0BACI;gBACEtD;gBACAc,QAAQwC;YACV,IACA;gBACEtD;YACF;YAGN,MAAM0D,qBACJ,OAAOrH,qBAAqB,WAExB,+CAA+C;YAC/CA,mBACA,MAAMuF,eAAevF;YAE3B,IAAIsE,SAAqCvD;YAEzC,kEAAkE;YAClE,MAAMuG,2BAA2BhG,gBAC7B9C,4BAA4B8C,iBAC5B;YACJ,MAAMiG,wBAAwBjG,gBAC1B/C,yBAAyB+C,iBACzB;YAEJ,IAAIiG,uBAAuB;gBACzB,MAAM/D,cACJlC,iBAAiBA,cAAcV,IAAI,KAAK,cACpCU,cAAckC,WAAW,GACzB;gBAEN,IAAIA,aAAa;oBACfA,YAAYgE,SAAS;gBACvB;gBACA,MAAMC,cAAcF,sBAAsBpB,KAAK,CAACS,GAAG,CAACS;gBACpD,IAAII,gBAAgB1G,WAAW;oBAC7B,MAAM2G,gBAAgB,MAAMD;oBAC5BpG,0BAA0BC,eAAeoG;oBACzC,IACEpG,kBAAkBP,aAClBO,cAAcV,IAAI,KAAK,eACvB8G,kBAAkB3G,aACjB2G,CAAAA,cAAclH,UAAU,KAAK,KAC5BkH,cAAcjH,MAAM,GAAGtB,cAAa,GACtC;wBACA,6EAA6E;wBAC7E,4EAA4E;wBAC5E,gFAAgF;wBAChF,gFAAgF;wBAChF,IAAIqE,aAAa;4BACfA,YAAYC,OAAO;wBACrB;wBACA,OAAO9E,mBACL2C,cAAcqG,YAAY,EAC1B;oBAEJ;oBACA,MAAM,CAAC3C,SAASC,QAAQ,GAAGyC,cAAchF,KAAK,CAACmC,GAAG;oBAClD6C,cAAchF,KAAK,GAAGuC;oBAEtB,IAAIzB,aAAa;wBACf,mEAAmE;wBACnE,gCAAgC;wBAChCc,SAAS4B,4BAA4BlB,SAASxB;oBAChD,OAAO;wBACLc,SAASU;oBACX;gBACF,OAAO;oBACL,IAAIxB,aAAa;wBACfA,YAAYC,OAAO;oBACrB;gBACF;YACF;YAEA,IAAIa,WAAWvD,WAAW;gBACxB,MAAMyC,cACJlC,iBAAiBA,cAAcV,IAAI,KAAK,cACpCU,cAAckC,WAAW,GACzB;gBACN,IAAIA,aAAa;oBACf,6EAA6E;oBAC7E,2DAA2D;oBAC3DA,YAAYgE,SAAS;gBACvB;gBAEA,MAAM1G,eACJQ,kBAAkBP,aAAaO,cAAcV,IAAI,KAAK,mBAClD,EAAE,GACFU,cAAcR,YAAY;gBAChC,MAAMS,QAAgC,MAAMoF,aAAaC,GAAG,CAC1DS,oBACAvG;gBAEF,MAAM8G,cAAc/D,YAAYC,UAAU,GAAGD,YAAYE,GAAG;gBAC5D,IACEzC,kBAAkBP,aAClBO,cAAcV,IAAI,KAAK,eACvBW,UAAUR,aACTQ,CAAAA,MAAMf,UAAU,KAAK,KAAKe,MAAMd,MAAM,GAAGtB,cAAa,GACvD;oBACA,6EAA6E;oBAC7E,4EAA4E;oBAC5E,gFAAgF;oBAChF,gFAAgF;oBAChF,IAAIqE,aAAa;wBACfA,YAAYC,OAAO;oBACrB;oBAEA,OAAO9E,mBACL2C,cAAcqG,YAAY,EAC1B;gBAEJ,OAAO,IACLpG,UAAUR,aACV6G,cAAcrG,MAAMgC,SAAS,GAAGhC,MAAMd,MAAM,GAAG,QAC9CZ,UAAUsE,kBAAkB,IAC3ByD,cAAcrG,MAAMgC,SAAS,GAAGhC,MAAMf,UAAU,GAAG,MACrD;oBACA,+BAA+B;oBAE/B,+EAA+E;oBAC/E,+EAA+E;oBAC/E,4EAA4E;oBAE5E,kFAAkF;oBAClF,mFAAmF;oBACnF,+EAA+E;oBAC/E,mFAAmF;oBACnF,6EAA6E;oBAE7E,MAAM,CAACqH,WAAWzC,kBAAkB,GAAG,MAAMxF,mBAC3CC,WACAyB,eACAvB,yBACAC,kBACAC;oBAGF,IAAI6H;oBACJ,IAAIR,0BAA0B;wBAC5B,8DAA8D;wBAC9D,MAAMhC,QAAQH,uBAAuBC;wBACrC0C,kBAAkBzC,iBAAiBC,OAAO;wBAC1CgC,yBAAyBnB,KAAK,CAACO,GAAG,CAChCW,oBACAhC,iBAAiBC,OAAO;oBAE5B,OAAO;wBACLwC,kBAAkB1C;oBACpB;oBAEA,MAAM2C,UAAUpB,aAAaD,GAAG,CAACW,oBAAoBS;oBAErD,IAAI,CAACjI,UAAUmI,uBAAuB,EAAE;wBACtCnI,UAAUmI,uBAAuB,GAAG,EAAE;oBACxC;oBACAnI,UAAUmI,uBAAuB,CAAClG,IAAI,CAACiG;oBAEvCzD,SAASuD;gBACX,OAAO;oBACLxG,0BAA0BC,eAAeC;oBAEzC,qDAAqD;oBACrD+C,SAAS/C,MAAMmB,KAAK;oBAEpB,qEAAqE;oBACrE,yBAAyB;oBACzB,IAAI4E,0BAA0B;wBAC5B,MAAM,CAACW,WAAWC,WAAW,GAAGnD,gBAAgBxD;wBAChD,IAAIiC,aAAa;4BACfc,SAAS4B,4BAA4B+B,UAAUvF,KAAK,EAAEc;wBACxD,OAAO;4BACLc,SAAS2D,UAAUvF,KAAK;wBAC1B;wBAEA4E,yBAAyBnB,KAAK,CAACO,GAAG,CAChCW,oBACAc,QAAQC,OAAO,CAACF;oBAEpB,OAAO;wBACL,kEAAkE;wBAClE,wEAAwE;wBACxE,kCAAkC;wBAClC1E,+BAAAA,YAAaC,OAAO;oBACtB;oBAEA,IAAImE,cAAcrG,MAAMgC,SAAS,GAAGhC,MAAMf,UAAU,GAAG,MAAM;wBAC3D,gFAAgF;wBAChF,mEAAmE;wBACnE,MAAM,CAAC6H,eAAejD,kBAAkB,GAAG,MAAMxF,mBAC/CC,WACAkB,WACAhB,yBACAC,kBACAC;wBAGF,IAAI6H;wBACJ,IAAIR,0BAA0B;4BAC5B,MAAMhC,QAAQH,uBAAuBC;4BACrC0C,kBAAkBzC,iBAAiBC,OAAO;4BAC1CgC,yBAAyBnB,KAAK,CAACO,GAAG,CAChCW,oBACAhC,iBAAiBC,OAAO;wBAE5B,OAAO;4BACLwC,kBAAkB1C;wBACpB;wBAEA,MAAM2C,UAAUpB,aAAaD,GAAG,CAC9BW,oBACAS;wBAGF,IAAI,CAACjI,UAAUmI,uBAAuB,EAAE;4BACtCnI,UAAUmI,uBAAuB,GAAG,EAAE;wBACxC;wBACAnI,UAAUmI,uBAAuB,CAAClG,IAAI,CAACiG;wBAEvC,MAAMM,cAAcC,MAAM;oBAC5B;gBACF;YACF;YAEA,yFAAyF;YACzF,0FAA0F;YAC1F,wFAAwF;YACxF,uFAAuF;YACvF,qFAAqF;YACrF,uFAAuF;YACvF,iFAAiF;YACjF,MAAMC,oBAAoB;YAE1B,MAAMC,yBAAyB;gBAC7B,2FAA2F;gBAC3F,yFAAyF;gBACzF,+CAA+C;gBAC/CC,eAAe;gBACfC,WAAW3J,gBACPgB,wBAAwB4I,oBAAoB,GAC5C5I,wBAAwB6I,gBAAgB;gBAC5CC,iBAAiBhK;YACnB;YAEA,OAAOV,yBAAyBmG,QAAQ;gBACtCkE;gBACA7E;gBACA4E;gBACA/D,iBAAiB;YACnB;QACF;IACF,CAAC,CAACqC,KAAK;IACP,OAAOC;AACT"}